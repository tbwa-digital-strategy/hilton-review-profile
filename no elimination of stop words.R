rm(list = ls())
options(scipen = 999)
options(stringsAsFactors = FALSE)

setwd("/Users/harro.cyranka/Desktop/projects/hilton_tripadvisor_review_collection/bigram_model_fit")
library(tidyverse);library(tidytext);library(glmnet);library(broom);library(wordcloud2)

x <- read_csv("hilton_review_data.csv")

y <- x %>%
  filter(rating != 30)

##
# Sample cases and fit model ----------------------------------------------
set.seed(5)
review_set <- y %>% filter(rating %in% c(10,20)) %>%
  bind_rows(x %>% filter(rating %in% c(40,50)) %>% sample_n(4190)) %>%
  mutate(review_n = row_number()) %>%
  rename(review = review_body) %>%
  mutate(review_type = factor(case_when(
    rating > 30 ~"Good",
    TRUE ~ "Bad"
  ))) %>%
  mutate(review_n = row_number()) 



##Put in tidy format
tidy_reviews <- review_set %>%
  select(review, review_type, review_n) %>%
  unnest_tokens(word, review,token = "ngrams", n = 2) %>%
  group_by(word) %>% filter(n() > 10)


sparse_matrix <- tidy_reviews %>%
  dplyr::count(review_n, word, sort = TRUE) %>%
  cast_sparse(review_n, word, n)


##
reviews_joined <- tibble(
  review_n = as.integer(rownames(sparse_matrix))) %>% 
  left_join(review_set) %>%
  select(review_n, review_type)


###
set.seed(1)
train_rows <- sample(1:8379, 6700)

##
#
response_model <- reviews_joined$review_type == "Good"


#Fit linear model
lasso_model <- cv.glmnet(
  sparse_matrix[train_rows,],
  y = response_model[train_rows],
  family = "binomial",
  alpha = 1,
  nfold = 10
)


saveRDS(lasso_model, "lasso_model_fit.RDS")
lasso_model <- readRDS("lasso_model_fit.RDS")

#Check the coefficients and retrieve coefficients of best model
model_coefficients <- lasso_model$glmnet.fit %>% tidy() %>%
  filter(lambda == lasso_model$lambda.min)


##
test_classifications <- tidy_reviews %>% filter(!review_n %in% train_rows) %>%
  inner_join(model_coefficients, by = c("word" = "term")) %>%
  dplyr::group_by(review_n) %>%
  dplyr::summarize(Score = sum(estimate)) %>%
  mutate(probability = arm::invlogit(-0.191 + Score)) %>%
  mutate(predictions = ifelse(probability > 0.5, "Good", "Bad"))%>% ##Change the threshold if necessary
  inner_join(review_set %>% select(review_n, review_type))

# train_classifications <- tidy_reviews %>% filter(review_n %in% train_rows) %>%
#   inner_join(model_coefficients, by = c("word" = "term")) %>%
#   dplyr::group_by(review_n) %>%
#   dplyr::summarize(Score = sum(estimate)) %>%
#   mutate(probability = arm::invlogit(-0.292 + Score)) %>%
#   mutate(predictions = ifelse(probability > 0.5, "Good", "Bad"))%>% ##Change the threshold if necessary
#   inner_join(review_set %>% select(review_n, review_type))
# 
# 
# joint_classifications <- bind_rows(train_classifications, test_classifications) %>%
#   filter(predictions == review_type) %>%
#   select(review_n, probability, review_type)

review_set %>% select(review,review_n) %>%
  inner_join(joint_classifications) %>%View()

##Create confusion matrix
confusion_matrix <- test_classifications %>%
  group_by(predictions, review_type) %>%
  tally() %>% spread(review_type,n)


#
facet_labs <- c(`Negative` = "",
                `Positive` = "")

model_coefficients %>%
  filter(term!="(Intercept)") %>%
  top_n(40, estimate) %>%
  arrange(desc(estimate)) %>%
  bind_rows(model_coefficients %>% filter(term!="(Intercept)") %>%
              top_n(n = -40,estimate)) %>%
  select(term, estimate) %>%
  mutate(charac = ifelse(estimate >0, "Positive", "Negative")) %>%
  filter(!term %in% c("bed very","i put")) %>%
  ggplot(aes(x = reorder(term, estimate), y = estimate, fill = charac)) +
  geom_col(show.legend = FALSE) + 
  facet_wrap(~charac, scales = "free_x",labeller = as_labeller(facet_labs)) + coord_flip() + 
  hrbrthemes::theme_ipsum_rc(strip_text_size = 13,axis_title_size = 15) +
  theme(
    panel.grid.major = element_line(size = 0.1,color = "gray90"),
    panel.grid.minor = element_blank(),
    panel.spacing = unit(-1.75,"cm")
  ) + 
  labs(x = "Word combination", y = "Coefficient",
       title = "Coefficients that decrease/increase probability of a positive review",
       subtitle = "Coefficients generated by a regularized linear model (supervised)")


##

